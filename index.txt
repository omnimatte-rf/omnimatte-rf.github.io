1:HL["/_next/static/media/e7c7dbb62ddcf6fa-s.p.woff2",{"as":"font","type":"font/woff2"}]
2:HL["/_next/static/css/4dc903766d1a074c.css",{"as":"style"}]
0:["kXAJ2tpOYVIyTDz-mBGsg",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],"$L3",[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/4dc903766d1a074c.css","precedence":"next"}]],["$L4",["$","meta",null,{"name":"next-size-adjust"}]]]]]]
5:HL["/_next/static/css/5baff23b1771b846.css",{"as":"style"}]
6:I{"id":"7477","chunks":["625:static/chunks/625-af5b057c6fb50add.js","185:static/chunks/app/layout-2c649f51bdc1c727.js"],"name":"","async":false}
7:I{"id":"7682","chunks":["625:static/chunks/625-af5b057c6fb50add.js","185:static/chunks/app/layout-2c649f51bdc1c727.js"],"name":"","async":false}
8:I{"id":"3211","chunks":["272:static/chunks/webpack-2dcfb94f7fcf1987.js","253:static/chunks/bce60fc1-fe2fbaac5e8de824.js","769:static/chunks/769-174e81ca6f91fa79.js"],"name":"","async":false}
9:I{"id":"5767","chunks":["272:static/chunks/webpack-2dcfb94f7fcf1987.js","253:static/chunks/bce60fc1-fe2fbaac5e8de824.js","769:static/chunks/769-174e81ca6f91fa79.js"],"name":"","async":false}
a:I{"id":"7218","chunks":["594:static/chunks/594-a265ff1a849d514a.js","931:static/chunks/app/page-536da1bffc24002d.js"],"name":"","async":false}
b:I{"id":"7668","chunks":["594:static/chunks/594-a265ff1a849d514a.js","931:static/chunks/app/page-536da1bffc24002d.js"],"name":"","async":false}
c:I{"id":"4222","chunks":["594:static/chunks/594-a265ff1a849d514a.js","931:static/chunks/app/page-536da1bffc24002d.js"],"name":"","async":false}
3:[["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_f9cc9d","children":["$","main",null,{"children":[[["$","section",null,{"className":"component_title__UkgDO","children":[["$","h1",null,{"children":[["$","strong",null,{"children":"OmnimatteRF"}],["$","br",null,{}],"Robust Omnimatte with 3D Background Modeling"]}],["$","span",null,{"className":"component_published__rjSpb","children":"ICCV 2023"}]]}],["$","section",null,{"className":"component_authorList__sLmCk","children":[["$","span","Geng Lin",{"className":"$undefined","children":[["$","a",null,{"href":"https://scholar.google.com/citations?user=2Vh_sboAAAAJ&hl=en","target":"_blank","children":"Geng Lin"}],["$","sup",null,{"children":"1"}]]}],["$","span","Chen Gao",{"className":"$undefined","children":[["$","a",null,{"href":"http://chengao.vision/","target":"_blank","children":"Chen Gao"}],["$","sup",null,{"children":"2"}]]}],["$","span","Jia-Bin Huang",{"className":"$undefined","children":[["$","a",null,{"href":"https://jbhuang0604.github.io/","target":"_blank","children":"Jia-Bin Huang"}],["$","sup",null,{"children":"1,2"}]]}],["$","span","Changil Kim",{"className":"$undefined","children":[["$","a",null,{"href":"https://changilkim.com/","target":"_blank","children":"Changil Kim"}],["$","sup",null,{"children":"2"}]]}],["$","span","Yipeng Wang",{"className":"$undefined","children":[["$","a",null,{"href":"https://www.linkedin.com/in/yipeng-wang99/","target":"_blank","children":"Yipeng Wang"}],["$","sup",null,{"children":"2"}]]}],["$","span","Matthias Zwicker",{"className":"$undefined","children":[["$","a",null,{"href":"https://www.cs.umd.edu/~zwicker/","target":"_blank","children":"Matthias Zwicker"}],["$","sup",null,{"children":"1"}]]}],["$","span","Ayush Saraf",{"className":"$undefined","children":[["$","a",null,{"href":"https://scholar.google.com/citations?user=bluhHm8AAAAJ&hl=en","target":"_blank","children":"Ayush Saraf"}],["$","sup",null,{"children":"2"}]]}]]}],["$","section",null,{"className":"component_affiliationList__i5VyJ","children":[["$","span","University of Maryland, College Park",{"className":"$undefined","children":[["$","sup",null,{"children":1}],"University of Maryland, College Park"]}],["$","span","Meta",{"className":"$undefined","children":[["$","sup",null,{"children":2}],"Meta"]}]]}]],["$","section",null,{"className":"component_links__O6lLr","children":[["$","$L6",null,{"className":"component_link__LvP1v","target":"_blank","href":"https://arxiv.org/abs/2309.07749","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","strokeWidth":1.5,"stroke":"currentColor","aria-hidden":"true","aria-labelledby":"$undefined","children":[null,["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M19.5 14.25v-2.625a3.375 3.375 0 00-3.375-3.375h-1.5A1.125 1.125 0 0113.5 7.125v-1.5a3.375 3.375 0 00-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 00-9-9z"}]]}]," Paper"]}],["$","$L6",null,{"className":"component_link__LvP1v","target":"_blank","href":"https://github.com/facebookresearch/OmnimatteRF","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","strokeWidth":1.5,"stroke":"currentColor","aria-hidden":"true","aria-labelledby":"$undefined","children":[null,["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M17.25 6.75L22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3l-4.5 16.5"}]]}]," Code (Coming Soon)"]}],["$","$L7",null,{}]]}],["$","section",null,{"className":"empty"}],["$","$L8",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","loading":"$undefined","loadingStyles":"$undefined","hasLoading":false,"template":["$","$L9",null,{}],"templateStyles":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","childProp":{"current":[[["$","section",null,{"className":"$undefined","children":["$","center",null,{"children":["$","video",null,{"src":"/matting-teaser.mp4","autoPlay":true,"loop":true,"muted":true}]}]}],["$","$La",null,{}],["$","section",null,{"className":"$undefined","children":[["$","h2",null,{"children":"Abstract"}],["$","p",null,{"children":" Video matting has broad applications, from adding interesting effects to casually captured movies to assisting video production professionals. Matting with associated effects like shadows and reflections has also attracted increasing research activity, and methods like Omnimatte have been proposed to separate foreground objects of interest into their own layers. However, prior works represent video backgrounds as 2D image layers, limiting their capacity to express more complicated scenes, thus hindering application to real-world videos. In this paper, we propose a novel video matting method, F2B3, that combines 2D foreground layers and a 3D background model. The 2D layers preserve the details of the subjects, while the 3D background robustly reconstructs scenes in real-world videos. Extensive experiments demonstrate that our method reconstructs with better quality on various videos."}]]}],["$","section",null,{"className":"component_method__8zQ7M","children":[["$","h2",null,{"children":"Method"}],["$","center",null,{"children":["$","img",null,{"src":"/overview.jpg"}]}],["$","p",null,{}],["$","p",null,{"children":["OmnimatteRF extends ",["$","i",null,{"children":"Omnimatting"}]," to a larger variety of real-world videos with a combination of 2D foreground layers and a background radiance field."]}]]}],["$","section",null,{"className":"component_datasets__fjKYl","children":[["$","h2",null,{"id":"data","children":"Data & Results"}],["$","$Lb",null,{}],["$","section",null,{"children":[["$","p",null,{}],["$","p",null,{"children":["Download our ",["$","span",null,{"className":"dataset","children":"Movies"}]," and ",["$","span",null,{"className":"dataset","children":"Wild"}]," datasets here: ",["$","a",null,{"target":"_blank","href":"https://drive.google.com/drive/folders/1PSEcqUR1prfQ51jzlCJ7tWDHPXmZGbMo?usp=sharing","children":"Google Drive"}]]}],["$","p",null,{"children":["The ",["$","span",null,{"className":"dataset","children":"Movies"}]," dataset contains 5 sequences from 3 Blender movies. They come with ground truth camera poses, object masks, and clean background videos."]}],["$","p",null,{"children":["Vidoes in ",["$","span",null,{"className":"dataset","children":"Wild"}]," are captured by us and come with reconstructed camera poses and coarse masks."]}],["$","p",null,{"children":["Other videos used in the paper are obtained from their authors: ",["$","a",null,{"target":"_blank","href":"https://davischallenge.org/davis2017/code.html","children":["$","span",null,{"className":"dataset","children":"DAVIS"}]}],", ",["$","a",null,{"target":"_blank","href":"https://d2nerf.github.io/","children":["$","span",null,{"className":"dataset","children":"Kubric"}]}],", ",["$","a",null,{"target":"_blank","href":"https://omnimatte.github.io/","children":"dogwalk"}]]}]]}]]}],["$","section",null,{"className":"$undefined","children":[["$","h2",null,{"children":"Presentation Video"}],["$","p",null,{"children":"Coming soon!"}]]}],["$","$Lc",null,{}]],null],"segment":"__PAGE__"},"styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/5baff23b1771b846.css","precedence":"next"}]]}]]}]}]}],null]
4:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"OmnimatteRF: Robust Omnimatte with 3D Background Modeling"}],["$","meta","2",{"name":"description","content":"OmnimatteRF: Robust Omnimatte with 3D Background Modeling"}],["$","meta","3",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
